---
title: "[AWS] CDKでVPCを後からマルチAZにしたらCIDRコンフリクトでハマった話"
emoji: ":thinking_face:"
type: "tech"
topics: [AWS, CDK, VPC]
published: false
---

こんにちは！ atama plus でエンジニアをしている zussy です。

この記事では、AWS CDK で**後から**マルチ AZ に変更するときに起こった問題とその解決策についてご紹介します。

同じ課題に遭遇した方の参考になれば幸いです。

# 経緯

コスト削減のため、最初は 1AZ で VPC を構築していました。「後でマルチ AZ に変更すればいいや」と軽く考えていたのですが、実際に変更しようとしたら CIDR コンフリクトが発生してしまいました。

CIDR 設計は事前に SRE チームに相談して、3AZ まで対応できるように設計してもらっていたのに、なぜコンフリクトが起きたのか...。調べてみると、CDK の VPC コンストラクトの仕様が原因でした。

この記事では、その問題と解決策についてまとめます。

# マルチ AZ 構成に変更したい

「マネコンで操作する分には設定変更ページでポチポチできた(気がする)ので、CDK でも簡単にできるだろう。」
そう思っていました。イメージは`availabilityZones[]`の配列に az を増やして`cdk deploy`するだけ（または`maxAzs`を 1→2 へ）。
しかしそんな簡単な問題ではありませんでした。

![](https://storage.googleapis.com/zenn-user-upload/6335536625d0-20251210.png)

```
The CIDR 'xx.xx.xx.x/xx' conflicts with another subnet
```

のエラーが発生しました。「マルチ AZ にしようとしてサブネット作ろうとしたけど、すでにその IP 範囲は使っているから競合しているよ」と怒られたのです。なぜこうなったかを詳細に説明していきます。

## 1AZ で構築していた理由

この時、下記のように実装していました

```typescript
const vpc = new ec2.Vpc(this, "VPC", {
  ipAddresses: ec2.IpAddresses.cidr("10.45.96.0/19"),
  availabilityZones: ["ap-northeast-1a"],
  subnetConfiguration: [
    {
      name: "Public",
      subnetType: ec2.SubnetType.PUBLIC,
      cidrMask: 24,
    },
    {
      name: "PrivateSubnetWithEgress",
      subnetType: ec2.SubnetType.PRIVATE_WITH_EGRESS,
      cidrMask: 22,
    },
    {
      name: "PrivateSubnetIsolated",
      subnetType: ec2.SubnetType.PRIVATE_ISOLATED,
      cidrMask: 24,
    },
  ],
});
```

L2 コンストラクトを使ったシンプルな VPC の設定です。
さらにここに書いている、`ipAddresses`(CIDR)や、各サブネットマスクは SRE チームに設計してもらった内容を反映しています。各サブネットに作成されるリソースを考慮して 3AZ までなら IP アドレスが枯渇することはないような設定です。その上で、「今マルチ AZ にするとお金もかかるし、その時が来たら増やせば良いだろう」そう思って最初は 1AZ で構築していました。

## 問題が発生した

実際に 1AZ で構築した際のサブネット構成は以下の通りでした：

- **VPC 全体**: `10.45.96.0/19`
- **Public**: `10.45.96.0/24`
- **PrivateSubnetWithEgress**: `10.45.100.0/22`
- **PrivateSubnetIsolated**: `10.45.104.0/24`

さて、時が経ち、マルチ AZ 構成に変更する必要が出てきました。`availabilityZones`に AZ を追加して`cdk deploy`を実行すると、冒頭で紹介したエラーが発生しました。

```
The CIDR 'xx.xx.xx.x/xx' conflicts with another subnet
```

なぜこのエラーが発生したのでしょうか？

## なぜ CIDR コンフリクトが起きたのか

CDK の VPC コンストラクトは、AZ を追加する際に**自動的にサブネットの CIDR を割り当てます**。しかし、この自動割り当てのロジックは、既存のサブネットの CIDR 範囲と競合する可能性があります。
実際に[issue](https://github.com/aws/aws-cdk/issues/6683)もあり、まだ改善はされていないみたいです...

#### どこに実装されているか

CDK の VPC L2 コンストラクトは**完全に「現在の定義だけ」を元に CIDR を再計算するステートレスなロジック**らしく、**既存サブネットの実体は考慮されない**みたいです。
ただ上記について公式の記述を見つけることができず、ライブラリの中身をちょっと覗いてみました。

- **Vpc L2 construct**: [`packages/aws-cdk-lib/aws-ec2/lib/vpc.ts`](https://github.com/aws/aws-cdk/blob/main/packages/aws-cdk-lib/aws-ec2/lib/vpc.ts)
- **IpAddresses / CIDR 割り当てロジック**: [`packages/aws-cdk-lib/aws-ec2/lib/ip-addresses.ts`](https://github.com/aws/aws-cdk/blob/main/packages/aws-cdk-lib/aws-ec2/lib/ip-addresses.ts)
- **NetworkBuilder**: `packages/aws-cdk-lib/aws-ec2/lib/network-util.ts`（`ip-addresses.ts`からインポートされている）

（CDK v2 / `aws-cdk-lib`パッケージ）
あたりにヒントがありそうです。
実際のソースコードを見ると、`ip-addresses.ts`では以下のように実装されています：

```typescript
import { NetworkBuilder } from "./network-util";

class Cidr implements IIpAddresses {
  private readonly networkBuilder: NetworkBuilder;

  constructor(private readonly cidrBlock: string) {
    this.networkBuilder = new NetworkBuilder(this.cidrBlock);
  }

  allocateSubnetsCidr(input: AllocateCidrRequest): SubnetIpamOptions {
    const allocatedSubnets: AllocatedSubnet[] = [];

    input.requestedSubnets.forEach((requestedSubnet, index) => {
      if (requestedSubnet.configuration.cidrMask === undefined) {
        // cidrMaskが未定義の場合の処理
      } else {
        allocatedSubnets.push({
          cidr: this.networkBuilder.addSubnet(
            requestedSubnet.configuration.cidrMask
          ),
        });
      }
    });

    return { allocatedSubnets };
  }
}
```

ポイントは、**`allocateSubnetsCidr()`メソッドが`input.requestedSubnets`（現在の定義）だけを見て、`NetworkBuilder.addSubnet()`を呼び出している**部分です。既存のサブネットの実体（AWS 上に実際に存在するサブネット）は一切参照されていません。

`IpAddresses.cidr()`を使う場合は`NetworkBuilder`が使われ、**現在の定義（`input.requestedSubnets`）だけを元に CIDR を計算**します。

つまり、AZ 数を 1 から 2 に変更すると：

1. `input.requestedSubnets`に 2AZ 分のサブネット定義が含まれる（例：Public(1AZ 目), Private(1AZ 目), Isolated(1AZ 目), Public(2AZ 目), Private(2AZ 目), Isolated(2AZ 目)）
2. `NetworkBuilder`は、この順序で CIDR を割り当てようとする
3. **AZ 数変更により 1AZ 目に再割り当てされようとした CIDR が、既存のサブネットと競合してしまう**

この時、既存のサブネットの CIDR は考慮されず、定義だけを元に全体を再計算するため、コンフリクトが発生するのです。

#### 実際に起きたパターン

1AZ で構築した時点では、以下のような割り当てになっていました：

- Public: `10.45.96.0/24`
- PrivateSubnetWithEgress: `10.45.100.0/22`
- PrivateSubnetIsolated: `10.45.104.0/24`

2AZ 目を追加しようとすると、CDK は**現在の定義（2AZ 分）を元に、全体の CIDR 割り当てを再計算**します。この時、既存のサブネットの実体（実際に AWS 上に存在するサブネット）は考慮されず、定義だけを見て「1AZ 目にはこの CIDR、2AZ 目にはこの CIDR」と割り当てようとします。

しかし、既に 1AZ 目のサブネットが存在しているため、**AZ 数変更により 1AZ 目に再割り当てされようとした CIDR が、既存のサブネットと競合してしまう**のです。

今回の場合、AZ 数を変更すると CDK が定義から全体の CIDR 割り当てを再計算するため、既存のサブネットの CIDR 範囲と被ってしまう可能性があります。

# 解決策

## 1: VPC 自体を作り直す

実際、これが許容されるなら一番シンプルに解決できる方法だと思います。丸っと削除してしまって、マルチ AZ にして作り直す。
ただ、VPC 自体の削除に伴い、それに紐づくリソースも影響を受けるのは間違いないので、一定のダウンタイムは必ず生じます。<br>さらに VPC の削除は結構面倒で、サブネットを削除しようとする時にそのサブネットにあるリソースに ENI がアタッチされていると CDK が削除しようとする → 失敗 → リトライ(３回)を繰り返し、50 分ほど時間がかけて、削除できずに終わるという悲惨なことになる場合もあります。(ここも書くと長くなりそうなのでまた別の機会に書きます)

https://repost.aws/ja/knowledge-center/lambda-delete-cloudformation-stack

## 2: `reservedAzs`を使う

この問題を解決する方法として、**`reservedAzs`**というプロパティがあります。

https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_ec2-readme.html#reserving-availability-zones

これは、VPC 作成時に将来使用する AZ を予約しておくことで、サブネットの CIDR 割り当てを事前に計画できるようにする機能です。

```typescript
const vpc = new ec2.Vpc(this, "VPC", {
  ipAddresses: ec2.IpAddresses.cidr("10.45.96.0/19"),
  maxAzs: 1, // 実際に作成するAZ数（availabilityZonesと同時指定は不可）
  reservedAzs: 2, // 将来使用するAZを2つ予約（合計3AZ分のCIDRが計画される）
  subnetConfiguration: [
    {
      name: "Public",
      subnetType: ec2.SubnetType.PUBLIC,
      cidrMask: 24,
    },
    {
      name: "PrivateSubnetWithEgress",
      subnetType: ec2.SubnetType.PRIVATE_WITH_EGRESS,
      cidrMask: 22,
    },
    {
      name: "PrivateSubnetIsolated",
      subnetType: ec2.SubnetType.PRIVATE_ISOLATED,
      cidrMask: 24,
    },
  ],
});
```

`reservedAzs: 2`を指定することで、CDK は最初から`maxAzs + reservedAzs = 3`AZ 分のサブネット CIDR を計画して割り当てます。これにより、後から AZ を追加する際に CIDR コンフリクトが発生しなくなります。

## `reservedAzs`を使った場合の CIDR 割り当て

実際に`reservedAzs: 2`を指定して構築した場合、以下のような CIDR 割り当てになりました：

### 1AZ 目（実際に作成されるサブネット）

- **Public**: `10.45.96.0/24`
- **PrivateSubnetWithEgress**: `10.45.100.0/22`
- **PrivateSubnetIsolated**: `10.45.112.0/24` ← 注意：1AZ 目でも`10.45.104.0/24`ではなく`10.45.112.0/24`が割り当てられました

### 2AZ 目（予約されているが、まだ作成されていない）

- **Public**: `10.45.97.0/24`
- **PrivateSubnetWithEgress**: `10.45.104.0/22`
- **PrivateSubnetIsolated**: `10.45.117.0/24`

diff だとこんな感じです。↓
![](https://storage.googleapis.com/zenn-user-upload/a956259c0f99-20251210.png)

このように、`reservedAzs`を使うと、**最初から複数 AZ 分の CIDR が計画されるため、サブネットの割り当てが変わります**。1AZ 目でも、将来的に 3AZ 分を考慮した CIDR 割り当てが行われるため、既存の設計通りの CIDR（`10.45.104.0/24`）ではなく、`10.45.112.0/24`が割り当てられました。

## 複数回試行して確認した結果

この挙動を確認するため、複数回デプロイを試行しましたが、何度試しても同じ結果になりました。つまり、`reservedAzs`を使うことで、CIDR 割り当てが一貫して行われることが確認できました。

## 後から`reservedAzs`を追加した場合

もし、最初に`reservedAzs`を指定せずに 1AZ で構築してしまった場合、後から`reservedAzs`を追加するとどうなるでしょうか？

この場合、**既存のサブネットの CIDR が再割り当てされます**。この場合も複数回試して実験してみたのですが、最初から指定した場合と同様の IP 範囲が毎回割り当たりました。
このとき CDK では新規サブネット作成 → 既存のサブネットを削除という手順を踏みます。結局サブネットの削除が発生するため、そこにあるリソース次第では削除に失敗する可能性があります。`reservedAzs`を指定してデプロイが通れば、その後の AZ 追加（`maxAzs`を増やす）では、**CIDR コンフリクトが発生しなくなります**が、できるだけ VPC 作成の時点で指定しておくのがベストでしょう。<br>

## まとめ

この記事では、AWS CDK で VPC を後からマルチ AZ に変更しようとした際に発生した CIDR コンフリクト問題と、その解決策について紹介しました。

CDK の VPC コンストラクトは、**現在の定義だけを元に CIDR を再計算するステートレスなロジック**のため、既存のサブネットの実体を考慮せずに CIDR を割り当てようとします。その結果、AZ 数を変更すると既存のサブネットと CIDR が競合してしまう可能性があります。

`reservedAzs`プロパティを使うことで、VPC 作成時に将来使用する AZ を予約しておけます。これにより、最初から複数 AZ 分の CIDR が計画されるため、後から AZ を追加してもコンフリクトが発生しません。

### 重要なポイント

- **最初から`reservedAzs`を指定しておくことがベスト**: 後から追加すると既存のサブネットが再作成される可能性があり、影響範囲が大きくなります
- **もしくは最初の VPC 作成時点でマルチ AZ にしてしまう**:金銭面が気にならないならこれが一番楽だと思います
- **CIDR 設計だけでは不十分**: 事前に CIDR 設計をしていても、CDK の自動割り当てロジックによってコンフリクトが発生する可能性があります
- **`reservedAzs`を使うと CIDR 割り当てが変わる**: 1AZ 目でも将来的な AZ を考慮した CIDR が割り当てられるため、既存の設計と異なる可能性があります

VPC 周りの設定変更は思っている以上に影響範囲が大きいので、最初から将来の拡張性を考慮した設計をしておくことが重要ですね。同じ問題に遭遇した方の参考になれば幸いです！